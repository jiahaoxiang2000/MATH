\documentclass[11pt,lang=en]{elegantbook}

\title{Abstract Algebra Note}
% \subtitle{Classic Elegant\LaTeX{} Template}

\author{isomo}
% \institute{Elegant\LaTeX{} Program}
\date{\today}
% \version{4.5}
% \bioinfo{Bio}{Information}

% \extrainfo{\textcolor{red}{\bfseries Caution: This template will no longer be maintained since January 1st, 2023.}}

% \logo{logo-blue.png}
\cover{cover.jpg}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}

% \addbibresource[location=local]{reference.bib} % bib

\begin{document}

\maketitle

\frontmatter
\tableofcontents

\mainmatter

\chapter{Group Theory}

\section{Monoid Group}

\begin{definition}{monoid}{monoid}
  We say that $(S, \ast)$ is a monoid if the binary operation satisfies the associative law and has an identity element. That is,
  \[
  \forall x, y, z \in S, \quad x \ast (y \ast z) = (x \ast y) \ast z
  \]
  and
  \[
  \exists e \in S, \forall x \in S, \quad e \ast x = x \ast e = x
  \]
\end{definition}


\begin{definition}{commutative monoid}{commutative monoid}
  We say that $(S, \ast)$ is a commutative monoid if it is a monoid and the operation satisfies the commutative law. That is,
  \[
  \forall x, y \in S, \quad x \ast y = y \ast x
  \]
\end{definition}

\begin{proposition}{unique of identity element}{uniqueness_of_identity_element}
  Let $(S, \cdot)$ be a monoid. Then the identity element is unique.
\end{proposition}
\begin{proof}
  Suppose that $e$ and $e'$ are both identity elements of $S$. Then
  \[
  e = e \cdot e' = e'
  \]
  so $e = e'$.
\end{proof}

\begin{proposition}{expand of associative law}{expand_of_associative_law}
  Let $x_1, \ldots, x_n, y_1, \ldots, y_m \in S$. Then
  \[
  x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
\end{proposition}
\begin{proof}
We prove this by induction on $n$.

\textbf{Base Case ($n = 1$):}  
When $n = 1$, the statement simplifies to:
\[
x_1 \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = x_1 \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
This is clearly true by the associative property of multiplication.

\textbf{Inductive Step:}  
Assume the statement holds for $n = k$, that is:
\[
x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
We need to show that the statement holds for $n = k + 1$. Consider:
\[
x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1} \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m
\]
By the associative property, we can regroup the terms as:
\[
(x_1 \cdot x_2 \cdot \ldots \cdot x_k ) \cdot (x_{k+1} \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
Using the inductive hypothesis on the first $k$ terms, we have:
\[
(x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot x_{k+1} \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m) = (x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1}) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
Thus, the statement holds for $n = k + 1$.

\end{proof}

\begin{proposition}
  Let $x \in S$ and $m,n \in \mathbb{N}$. Then
  \[
  x^{m+n} = x^m \cdot x^n
  \]
\end{proposition}
\begin{proof}
  We will prove this in three steps:

  \textbf{Step 1:} First, recall from Proposition~\ref{pro:expand_of_associative_law} that for any elements in $S$:
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]

  \textbf{Step 2:} Now, consider the special case where all elements are equal to $x$:
  \begin{itemize}
    \item Let $x_1 = x_2 = \ldots = x_m = x$
    \item Let $y_1 = y_2 = \ldots = y_n = x$
  \end{itemize}

  \textbf{Step 3:} By definition of exponentiation in a monoid:
  \begin{align*}
    x^{m+n} &= \underbrace{x \cdot x \cdot \ldots \cdot x}_{m+n \text{ times}} \\
    &= (\underbrace{x \cdot x \cdot \ldots \cdot x}_{m \text{ times}}) \cdot (\underbrace{x \cdot x \cdot \ldots \cdot x}_{n \text{ times}}) \\
    &= x^m \cdot x^n
  \end{align*}

  Therefore, we have proved that $x^{m+n} = x^m \cdot x^n$ for all $x \in S$ and $m,n \in \mathbb{N}$.
\end{proof}

\begin{definition}{Submonoid}{submonoid}
  Let $(S,\cdot)$ be a monoid. If $T \subset S$, we say that $(T,\cdot)$ is a submonoid of $(S,\cdot)$ if:
  \begin{enumerate}
    \item The identity element $e \in T$
    \item $T$ is closed under multiplication, that is:
    \[
      \forall x,y \in T, \quad x \cdot y \in T
    \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  If $(T,\cdot)$ is a submonoid of $(S,\cdot)$, then $(T,\cdot)$ is a monoid.
\end{proposition}
\begin{proof}
  We need to verify two properties:
  \begin{enumerate}
    \item The operation is associative in $T$: \\
    Since $T \subset S$ and $\cdot$ is associative in $S$, it is also associative in $T$.
    
    \item $T$ has an identity element: \\
    By definition of submonoid, the identity element $e \in T$.
  \end{enumerate}
  Therefore, $(T,\cdot)$ satisfies all properties of a monoid.
\end{proof}

\begin{definition}[Monoid Homomorphism]{monoid_homomorphism}
  Let $(S,\cdot)$ and $(T,\ast)$ be monoids, and let $f : S \to T$ be a mapping. 
  We say $f$ is a monoid homomorphism if $f$ preserves multiplication and maps the identity element to the identity element. That is:
  \begin{enumerate}
    \item For all $x,y \in S$:
    \[
      f(x \cdot y) = f(x) \ast f(y) 
    \]
    \item For the identity elements $e \in S$ and $e' \in T$:
    \[
      f(e) = e' 
    \]
  \end{enumerate}
\end{definition}

\begin{remark}
  While a homomorphism preserves operations, an isomorphism represents complete structural equivalence. An isomorphism is first a \textbf{bijective mapping}, meaning it establishes a one-to-one correspondence between elements - essentially ``relabeling" elements uniquely. Beyond being bijective, an isomorphism preserves operations under this relabeling, implying that the only difference between two structures (like monoids) is their labeling.
\end{remark}

\begin{example}[~Different Types of Monoid Maps]
  Let's examine several maps between monoids:

  \begin{enumerate}
    \item \textbf{A homomorphism that is not an isomorphism:} 
     Consider $f: (\mathbb{Z}, +) \to (\mathbb{Z}, +)$ defined by $f(n) = 2n$
    \begin{itemize}
      \item Preserves operation: $f(a + b) = 2(a + b) = 2a + 2b = f(a) + f(b)$
      \item Is injective: $f(a) = f(b) \implies 2a = 2b \implies a = b$
      \item Not surjective: odd numbers are not in the image
      \item Therefore: homomorphism but not isomorphism
    \end{itemize}
    \item \textbf{Non-isomorphic homomorphism:} 
    Consider $h: (\mathbb{Z}, +) \to (\mathbb{Z}_2, +)$ defined by $h(n) = n \bmod 2$
    \begin{itemize}
      \item Preserves operation: $h(a + b) = (a + b) \bmod 2 = (a \bmod 2 + b \bmod 2) \bmod 2 = h(a) + h(b)$
      \item Not injective: $h(0) = h(2) = 0$
      \item Surjective: image is all of $\mathbb{Z}_2$
      \item Therefore: homomorphism but not isomorphism
    \end{itemize}
  \end{enumerate}
\end{example}

\begin{definition}[Generated Submonoid]
  Let $(S,\cdot)$ be a monoid and $A \subset S$ be a subset. The submonoid generated by $A$, denoted by $\langle A \rangle$, is defined as the intersection of all submonoids of $S$ containing $A$. That is:
  \[
    \langle A \rangle = \bigcap \{T \subset S : T \supset A, \text{ $T$ is a submonoid}\}
  \]
\end{definition}

\begin{proposition}
  Let $(S,\cdot)$ be a monoid and $A \subset S$ be a subset. Then $\langle A \rangle$ is also a submonoid. Therefore, it is the smallest submonoid containing $A$.
\end{proposition}
\begin{proof}
  We will prove this in two steps:

  \textbf{Step 1:} Show $\langle A \rangle$ contains the identity element 
  
  Let $\{T_\alpha\}_{\alpha \in I}$ be the collection of all submonoids containing $A$,
  Each $T_\alpha$ contains the identity $e$ (by definition of submonoid),
  Therefore $e \in \bigcap_{\alpha \in I} T_\alpha = \langle A \rangle$

  \textbf{Step 2:} Show closure under multiplication
  
     Let $x, y \in \langle A \rangle = \bigcap_{\alpha \in I} T_\alpha$,
     Then $x, y \in T_\alpha$ for all $\alpha \in I$
     Since each $T_\alpha$ is a submonoid, $x \cdot y \in T_\alpha$ for all $\alpha \in I$,
     Therefore $x \cdot y \in \bigcap_{\alpha \in I} T_\alpha = \langle A \rangle$.
  
\end{proof}

\begin{definition}[Monoid Isomorphism]
  Let $(S,\cdot)$ and $(T,\ast)$ be monoids, and let $f : S \to T$ be a mapping. We say $f$ is a monoid isomorphism if $f$ is bijective and a homomorphism. That is:
  \begin{enumerate}
    \item $f$ is bijective (one-to-one and onto) 
    \item For all $x,y \in S$:
    \[
      f(x \cdot y) = f(x) \ast f(y) 
    \]
    \item For the identity elements $e \in S$ and $e' \in T$:
    \[
      f(e) = e' 
    \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  If $f : (S,\cdot) \to (T,\ast)$ is a monoid isomorphism, then $f^{-1} : T \to S$ is a monoid homomorphism. Therefore, $f^{-1}$ is also a monoid isomorphism.
\end{proposition}

\begin{proof}
  Since $f$ is an isomorphism, $f^{-1}$ exists and is bijective. We need to show:
  \begin{enumerate}
    \item $f^{-1}$ preserves operation:
    \begin{align*}
      f^{-1}(a \ast b) &= f^{-1}(f(f^{-1}(a)) \ast f(f^{-1}(b))) \\
      &= f^{-1}(f(f^{-1}(a) \cdot f^{-1}(b))) \\
      &= f^{-1}(a) \cdot f^{-1}(b)
    \end{align*}
    
    \item $f^{-1}$ preserves identity:
    \[
      f^{-1}(e') = e \text{ where $e'$ and $e$ are identity elements}
    \]
  \end{enumerate}
  Therefore, $f^{-1}$ is both a homomorphism and bijective, making it an isomorphism.
\end{proof}

\chapter{Ring Theory}

\chapter{Ring Theory}

\chapter{Polynomial Theory}

\chapter{Field Theory}



%\problemset

% \printbibliography[heading=bibintoc, title=\ebibname]
% \appendix


% \chapter{Mathematical Tools}

% This appendix covers some of the basic mathematics used in econometrics. We briefly discuss the properties of summation operators, study the properties of linear and some nonlinear equations, and  also introduce some special functions that are common in econometrics applications, including quadratic functions and natural logarithms. The first four sections require only basic algebraic techniques. The fifth section briefly reviews differential Calculus Although Calculus is not necessary to understand much of this book, it is used in some of the end-of-chapter appendices and in some of the more advanced topics in part 3.

% \section{Summation Operator and Description Statistics}

% \textbf{Summation Operator} is an abbreviation used to express the summation of numbers, it plays an important role in statistics and econometrics analysis. If $\{x_i: i=1, 2, \ldots, n\}$ is a sequence of $n$ numbers, the summation of the $n$ numbers is:




\end{document}