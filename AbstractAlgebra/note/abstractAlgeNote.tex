\documentclass[11pt,lang=en]{elegantbook}

\title{Abstract Algebra Note}
% \subtitle{Classic Elegant\LaTeX{} Template}

\author{isomo}
% \institute{Elegant\LaTeX{} Program}
\date{\today}
% \version{4.5}
% \bioinfo{Bio}{Information}

% \extrainfo{\textcolor{red}{\bfseries Caution: This template will no longer be maintained since January 1st, 2023.}}

% \logo{logo-blue.png}
\cover{cover.jpg}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}

% \addbibresource[location=local]{reference.bib} % bib

\begin{document}

\maketitle

\frontmatter
\tableofcontents

\mainmatter

\chapter{Group Theory}

\section{Monoid Group}

\begin{definition}{monoid}{monoid}
  We say that $(S, \ast)$ is a monoid if the binary operation satisfies the associative law and has an identity element. That is,
  \[
  \forall x, y, z \in S, \quad x \ast (y \ast z) = (x \ast y) \ast z
  \]
  and
  \[
  \exists e \in S, \forall x \in S, \quad e \ast x = x \ast e = x
  \]
\end{definition}


\begin{definition}{commutative monoid}{commutative monoid}
  We say that $(S, \ast)$ is a commutative monoid if it is a monoid and the operation satisfies the commutative law. That is,
  \[
  \forall x, y \in S, \quad x \ast y = y \ast x
  \]
\end{definition}

\begin{proposition}{unique of identity element}{uniqueness_of_identity_element}
  Let $(S, \cdot)$ be a monoid. Then the identity element is unique.
\end{proposition}
\begin{proof}
  Suppose that $e$ and $e'$ are both identity elements of $S$. Then
  \[
  e = e \cdot e' = e'
  \]
  so $e = e'$.
\end{proof}

\begin{proposition}{expand of associative law}{expand_of_associative_law}
  Let $x_1, \ldots, x_n, y_1, \ldots, y_m \in S$. Then
  \[
  x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
\end{proposition}
\begin{proof}
We prove this by induction on $n$.

\textbf{Base Case ($n = 1$):}  
When $n = 1$, the statement simplifies to:
\[
x_1 \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = x_1 \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
This is clearly true by the associative property of multiplication.

\textbf{Inductive Step:}  
Assume the statement holds for $n = k$, that is:
\[
x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
We need to show that the statement holds for $n = k + 1$. Consider:
\[
x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1} \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m
\]
By the associative property, we can regroup the terms as:
\[
(x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1}) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
Using the inductive hypothesis on the first $k$ terms, we have:
\[
(x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot x_{k+1} \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m) = (x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1}) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
\]
Thus, the statement holds for $n = k + 1$.

\end{proof}

\begin{proposition}
  Let $x \in S$ and $m,n \in \mathbb{N}$. Then
  \[
  x^{m+n} = x^m \cdot x^n
  \]
\end{proposition}
\begin{proof}
  We will prove this in three steps:

  \textbf{Step 1:} First, recall from Proposition~\ref{pro:expand_of_associative_law} that for any elements in $S$:
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]

  \textbf{Step 2:} Now, consider the special case where all elements are equal to $x$:
  \begin{itemize}
    \item Let $x_1 = x_2 = \ldots = x_m = x$
    \item Let $y_1 = y_2 = \ldots = y_n = x$
  \end{itemize}

  \textbf{Step 3:} By definition of exponentiation in a monoid:
  \begin{align*}
    x^{m+n} &= \underbrace{x \cdot x \cdot \ldots \cdot x}_{m+n \text{ times}} \\
    &= (\underbrace{x \cdot x \cdot \ldots \cdot x}_{m \text{ times}}) \cdot (\underbrace{x \cdot x \cdot \ldots \cdot x}_{n \text{ times}}) \\
    &= x^m \cdot x^n
  \end{align*}

  Therefore, we have proved that $x^{m+n} = x^m \cdot x^n$ for all $x \in S$ and $m,n \in \mathbb{N}$.
\end{proof}

\begin{definition}{Submonoid}{submonoid}
  Let $(S,\cdot)$ be a monoid. If $T \subset S$, we say that $(T,\cdot)$ is a submonoid of $(S,\cdot)$ if:
  \begin{enumerate}
    \item The identity element $e \in T$
    \item $T$ is closed under multiplication, that is:
    \[
      \forall x,y \in T, \quad x \cdot y \in T
    \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  If $(T,\cdot)$ is a submonoid of $(S,\cdot)$, then $(T,\cdot)$ is a monoid.
\end{proposition}
\begin{proof}
  We need to verify two properties:
  \begin{enumerate}
    \item The operation is associative in $T$: \\
    Since $T \subset S$ and $\cdot$ is associative in $S$, it is also associative in $T$.
    
    \item $T$ has an identity element: \\
    By definition of submonoid, the identity element $e \in T$.
  \end{enumerate}
  Therefore, $(T,\cdot)$ satisfies all properties of a monoid.
\end{proof}

\begin{definition}[Monoid Homomorphism]{monoid_homomorphism}
  Let $(S,\cdot)$ and $(T,\ast)$ be monoids, and let $f : S \to T$ be a mapping. 
  We say $f$ is a monoid homomorphism if $f$ preserves multiplication and maps the identity element to the identity element. That is:
  \begin{enumerate}
    \item For all $x,y \in S$:
    \[
      f(x \cdot y) = f(x) \ast f(y) 
    \]
    \item For the identity elements $e \in S$ and $e' \in T$:
    \[
      f(e) = e' 
    \]
  \end{enumerate}
\end{definition}

\begin{remark}
  While a homomorphism preserves operations, an isomorphism represents complete structural equivalence. An isomorphism is first a \textbf{bijective mapping}, meaning it establishes a one-to-one correspondence between elements - essentially ``relabeling" elements uniquely. Beyond being bijective, an isomorphism preserves operations under this relabeling, implying that the only difference between two structures (like monoids) is their labeling.
\end{remark}

\begin{example}[~Different Types of Monoid Maps]
  Let's examine several maps between monoids:

  \begin{enumerate}
    \item \textbf{A homomorphism that is not an isomorphism:} 
     Consider $f: (\mathbb{Z}, +) \to (\mathbb{Z}, +)$ defined by $f(n) = 2n$
    \begin{itemize}
      \item Preserves operation: $f(a + b) = 2(a + b) = 2a + 2b = f(a) + f(b)$
      \item Is injective: $f(a) = f(b) \implies 2a = 2b \implies a = b$
      \item Not surjective: odd numbers are not in the image
      \item Therefore: homomorphism but not isomorphism
    \end{itemize}
    \item \textbf{Another non-isomorphic homomorphism:} 
    Consider $h: (\mathbb{Z}, +) \to (\mathbb{Z}_2, +)$ defined by $h(n) = n \bmod 2$
    \begin{itemize}
      \item Preserves operation: $h(a + b) = (a + b) \bmod 2 = (a \bmod 2 + b \bmod 2) \bmod 2 = h(a) + h(b)$
      \item Not injective: $h(0) = h(2) = 0$
      \item Surjective: image is all of $\mathbb{Z}_2$
      \item Therefore: homomorphism but not isomorphism
    \end{itemize}
    \item \textbf{An isomorphism:} 
     Consider $g: (\mathbb{Z}, +) \to (\mathbb{Z}, +)$ defined by $g(n) = -n$
    \begin{itemize}
      \item Preserves operation: $g(a + b) = -(a + b) = -a + (-b) = g(a) + g(b)$
      \item Bijective: one-to-one correspondence
      \item Has inverse function: $g^{-1}(n) = -n$
      \item Therefore: isomorphism
    \end{itemize}
    \item \textbf{An isomorphism between different monoids:} 
    \begin{itemize}
      \item Homomorphisms preserve structure but may "collapse" elements
      \item Isomorphisms preserve both structure and distinctness of elements
      \item The same set can have different monoid structures that are isomorphic
    \end{itemize}
  \end{enumerate}

\end{example}
\chapter{Ring Theory}

\chapter{Polynomial Theory}

\chapter{Field Theory}



%\problemset

% \printbibliography[heading=bibintoc, title=\ebibname]
% \appendix


% \chapter{Mathematical Tools}

% This appendix covers some of the basic mathematics used in econometrics. We briefly discuss the properties of summation operators, study the properties of linear and some nonlinear equations, and review the ratios and percentages. We also introduce some special functions that are common in econometrics applications, including quadratic functions and natural logarithms. The first four sections require only basic algebraic techniques. The fifth section briefly reviews differential Calculus Although Calculus is not necessary to understand much of this book, it is used in some of the end-of-chapter appendices and in some of the more advanced topics in part 3.

% \section{Summation Operator and Description Statistics}

% \textbf{Summation Operator} is an abbreviation used to express the summation of numbers, it plays an important role in statistics and econometrics analysis. If $\{x_i: i=1, 2, \ldots, n\}$ is a sequence of $n$ numbers, the summation of the $n$ numbers is:




\end{document}