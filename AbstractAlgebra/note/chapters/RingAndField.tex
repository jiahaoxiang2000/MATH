
\chapter{Ring, Field and Polynomial}

\section{Ring \& Field}

\begin{definition}[Ring]
  A ring is a tuple $(R,+,\cdot,0_R,1_R)$ where $R$ is a set, $0_R,1_R \in R$, and $+: R \times R \to R$ and $\cdot: R \times R \to R$ are binary operations satisfying:
  \begin{enumerate}
    \item Addition satisfies:
      \begin{itemize}
        \item Associativity: $(x + y) + z = x + (y + z)$
        \item Identity: $x + 0_R = x = 0_R + x$
        \item Commutativity: $x + y = y + x$
        \item Inverse: For all $x$ there exists $-x$ with $x + (-x) = 0_R$
      \end{itemize}

    \item Multiplication (written as $xy$ for $x \cdot y$) satisfies:
      \begin{itemize}
        \item Associativity: $(xy)z = x(yz)$
        \item Identity: $x \cdot 1_R = x = 1_R \cdot x$
      \end{itemize}

    \item Distributive Laws:
      \begin{itemize}
        \item $(x + y)z = xz + yz$
        \item $z(x + y) = zx + zy$
      \end{itemize}
  \end{enumerate}
  Where $x,y,z$ represent arbitrary elements of $R$. When no confusion arises, we write $0_R, 1_R$ as $0,1$ and denote the ring by $R$. We write $x + (-y)$ as $x - y$.
\end{definition}

\begin{definition}[Subring]
  Let $R$ be a ring. A subset $R_0 \subseteq R$ containing $0_R, 1_R$ is called a subring of $R$ if it is closed under:
  \begin{itemize}
    \item Addition: $x,y \in R_0 \implies x + y \in R_0$
    \item Multiplication: $x,y \in R_0 \implies xy \in R_0$
    \item Additive inverse: $x \in R_0 \implies -x \in R_0$
  \end{itemize}
  Then $(R_0,+,\cdot,0_R,1_R)$ forms a ring.
\end{definition}

\begin{definition}[Ring Invertibility]
  Let $x$ be an element of a ring $R$.
  \begin{itemize}
    \item If there exists $y \in R$ such that $xy = 1$ (resp. $yx = 1$), then $y$ is called a right inverse (resp. left inverse) of $x$
    \item $x$ is called right invertible (resp. left invertible) if it has a right (resp. left) inverse
    \item $x$ is called invertible if it has both left and right inverses
  \end{itemize}
  The set of invertible elements in $R$ is denoted by $R^\times$.
\end{definition}

\begin{proposition}[Uniqueness of Ring Inverses]
  If an element $x$ in a ring $R$ is invertible, then:
  \begin{enumerate}
    \item Its left inverse is also its right inverse
    \item There exists a unique $x^{-1} \in R$ such that $x^{-1}x = 1 = xx^{-1}$
    \item $(x^{-1})^{-1} = x$
  \end{enumerate}
\end{proposition}

\begin{proof}
  Let $y$ be a left inverse and $z$ a right inverse of $x$.
  Then $y = y(xz) = (yx)z = z$.
  Therefore, $y = z = x^{-1}$ is the unique two-sided inverse.
  Clearly $(x^{-1})^{-1} = x$ by definition.
\end{proof}

\begin{definition}[Commutative Ring]
  A ring $R$ is called commutative if its multiplication is commutative, i.e.,
  \[
    xy = yx \text{ for all } x,y \in R
  \]
\end{definition}

\begin{definition}[Division Ring and Field]
  A ring $R$ is called a division ring if $R^\times = R \setminus \{0\}$ (i.e., every non-zero element is invertible).
  A commutative division ring is called a field.
  A subring of a field that is itself a field is called a subfield.
\end{definition}

\begin{definition}[Integral Domain]{integral_domain}
  A non-zero commutative ring $R$ is called an integral domain if for all $x,y \in R$:
  \[
    x,y \neq 0 \implies xy \neq 0
  \]
\end{definition}

\section{homomorphism \& isomorphism}

\begin{definition}[Ring Homomorphism]
  Let $f : R \to R'$ be a mapping between rings. We call $f$ a ring homomorphism if:
  \begin{itemize}
    \item $f(x + y) = f(x) + f(y)$
    \item $f(xy) = f(x)f(y)$
    \item $f(1_R) = 1_{R'}$
  \end{itemize}
  for all $x,y \in R$. A homomorphism from a ring to itself is called an endomorphism.
\end{definition}

\begin{definition}[Ring Isomorphism]
  Let $f : R \to R'$ be a ring homomorphism. We call $f$ a ring isomorphism if there exists a ring homomorphism $g : R' \to R$ such that:
  \[
    g \circ f = \text{id}_R \text{ and } f \circ g = \text{id}_{R'}
  \]
  In this case, $g$ is called the inverse of $f$, and we say $R$ and $R'$ are isomorphic.
\end{definition}

\begin{proposition}
  If $f : R \to R'$ is a ring homomorphism that is bijective as a set mapping, then $f$ is a ring isomorphism.
\end{proposition}

\begin{proof}
  Let $g : R' \to R$ be the inverse of $f$ as a set mapping.
  We need to show $g$ is a ring homomorphism:
  \begin{itemize}
    \item For addition: $g(x' + y') = g(f(g(x')) + f(g(y'))) = g(x') + g(y')$
    \item For multiplication: $g(x'y') = g(f(g(x'))f(g(y'))) = g(x')g(y')$
    \item For identity: $g(1_{R'}) = g(f(1_R)) = 1_R$
  \end{itemize}
  Therefore $g$ is a ring homomorphism and $f$ is an isomorphism.
\end{proof}

\begin{proposition}[Chinese Remainder Theorem - Ring Version]
  Let $N \in \mathbb{Z}_{\geq 1}$ factor as $N = n_1\cdots n_k$ where $n_1,\ldots,n_k$ are pairwise coprime. Then there exists a ring isomorphism:
  \[
    \varphi: \mathbb{Z}/N\mathbb{Z} \xrightarrow{\sim} \prod_{i=1}^k \mathbb{Z}/n_i\mathbb{Z}
  \]
  given by $[x]_N \mapsto ([x]_{n_i})_{i=1}^k$
\end{proposition}
\begin{proof}
  \begin{enumerate}
    \item \textbf{Well-defined:} If $x \equiv y \pmod{N}$, then $x \equiv y \pmod{n_i}$ for all $i$

    \item \textbf{Ring homomorphism:}
      \begin{itemize}
        \item $\varphi([x]_N + [y]_N) = \varphi([x+y]_N) = ([x+y]_{n_i}) = ([x]_{n_i} + [y]_{n_i})$
        \item $\varphi([x]_N[y]_N) = \varphi([xy]_N) = ([xy]_{n_i}) = ([x]_{n_i}[y]_{n_i})$
      \end{itemize}

    \item \textbf{Injective:} If $\varphi([x]_N) = \varphi([y]_N)$, then $x \equiv y \pmod{n_i}$ for all $i$.
      Since $n_i$ are coprime, $x \equiv y \pmod{N}$

    \item \textbf{Surjective:} Given $([a_i]_{n_i})$, by CRT there exists $x$ with $x \equiv a_i \pmod{n_i}$.
      Then $\varphi([x]_N) = ([a_i]_{n_i})$
  \end{enumerate}
\end{proof}

\begin{example}[Application of Chinese Remainder Theorem]
  Find $x$ satisfying the system of congruences:
  \begin{align*}
    x &\equiv 2 \pmod{3} \\
    x &\equiv 3 \pmod{5} \\
    x &\equiv 2 \pmod{7}
  \end{align*}

  Solution:
  \begin{enumerate}
    \item $N = 3 \cdot 5 \cdot 7 = 105$
    \item Find $M_i$:
      \begin{itemize}
        \item $M_1 = 35$ (for mod 3)
        \item $M_2 = 21$ (for mod 5)
        \item $M_3 = 15$ (for mod 7)
      \end{itemize}
    \item Find $y_i$ where $M_iy_i \equiv 1 \pmod{n_i}$:
      \begin{itemize}
        \item $35y_1 \equiv 1 \pmod{3} \implies y_1 = 2$
        \item $21y_2 \equiv 1 \pmod{5} \implies y_2 = 1$
        \item $15y_3 \equiv 1 \pmod{7} \implies y_3 = 1$
      \end{itemize}
    \item $x = (2 \cdot 35 \cdot 2 + 3 \cdot 21 \cdot 1 + 2 \cdot 15 \cdot 1) \pmod{105} = 23$
  \end{enumerate}

  Verify: $23 \equiv 2 \pmod{3}$, $23 \equiv 3 \pmod{5}$, $23 \equiv 2 \pmod{7}$
\end{example}

\section{Polynomial Ring}

\begin{definition}[Polynomial Ring]
  Let $R$ be a non-zero ring. A polynomial in variable $X$ with coefficients in $R$ is defined as a formal sum:
  \[
    f = \sum_{n \geq 0} a_nX^n, \quad a_n \in R
  \]
  where only finitely many $a_n$ are non-zero. Terms with $a_n = 0$ may be omitted. When emphasis on the variable is needed, we write $f(X)$. The set of all such polynomials is denoted $R[X]$.
\end{definition}

\begin{definition}[Operations on Polynomials]
  Addition of polynomials is defined term by term:
  \[
    \sum_{n \geq 0} a_nX^n + \sum_{n \geq 0} b_nX^n := \sum_{n \geq 0} (a_n + b_n)X^n
  \]

  Multiplication is defined by convolution:
  \[
    \left(\sum_{n \geq 0} a_nX^n\right) \cdot \left(\sum_{n \geq 0} b_nX^n\right) := \sum_{n \geq 0} \left(\sum_{h+k=n} a_hb_k\right)X^n
  \]
\end{definition}

\begin{proposition}[Ring Structure of Polynomials]
  With the above operations, $R[X]$ forms a ring where:
  \begin{enumerate}
    \item The zero polynomial is $0_{R[X]}$
    \item The unit polynomial is the constant polynomial $1_{R[X]}$ corresponding to $1_R$
    \item $R$ embeds as a subring of $R[X]$
    \item If $R$ is commutative, then $R[X]$ is also commutative
  \end{enumerate}
\end{proposition}

\begin{lemma}[Degree Properties in Integral Domains]
  Let $R$ be an integral domain (Definition~\ref{def:integral_domain}). Then for all non-zero $f,g \in R[X]$:
  \[
    \deg(fg) = \deg f + \deg g
  \]
  Consequently:
  \begin{enumerate}
    \item $R[X]$ is also an integral domain
    \item $R[X]^\times = R^\times$
  \end{enumerate}
\end{lemma}

\begin{definition}[Homogeneous Polynomials]
  Let $f = \sum_{a_1,\ldots,a_n \geq 0} c_{a_1,\ldots,a_n} X_1^{a_1}\cdots X_n^{a_n}$ be an element of $R[X_1,\ldots,X_n]$.

  $f$ is called homogeneous of degree $N$ if there exists $N \in \mathbb{Z}_{\geq 0}$ such that $c_{a_1,\ldots,a_n} \neq 0$ implies $a_1 + \cdots + a_n = N$.
\end{definition}

\begin{remark}
  This concept extends naturally to polynomial rings with infinitely many variables, as they can be written as unions of subrings with finitely many variables.
\end{remark}

\begin{definition}[Polynomial Composition]
  Let $R$ be a commutative ring. For $n,m \in \mathbb{Z}_{\geq 1}$, given:
  \[
    f = \sum_{a_1,\ldots,a_n \geq 0} c_{a_1,\ldots,a_n} X_1^{a_1}\cdots X_n^{a_n} \in R[X_1,\ldots,X_n]
  \]
  and $g_1,\ldots,g_n \in R[Y_1,\ldots,Y_m]$

  Let $g := (g_1,\ldots,g_n) \in R[Y_1,\ldots,Y_m]^n$. The composition is defined as:
  \[
    f \circ g := \sum_{a_1,\ldots,a_n \geq 0} c_{a_1,\ldots,a_n} g_1^{a_1}\cdots g_n^{a_n} \in R[Y_1,\ldots,Y_m]
  \]
\end{definition}

\section{Monoid Group}

\begin{definition}{monoid}{monoid}
  We say that $(S, \ast)$ is a monoid if the binary operation satisfies the associative law and has an identity element. That is,
  \[
    \forall x, y, z \in S, \quad x \ast (y \ast z) = (x \ast y) \ast z
  \]
  and
  \[
    \exists e \in S, \forall x \in S, \quad e \ast x = x \ast e = x
  \]
\end{definition}

\begin{definition}{commutative monoid}{commutative monoid}
  We say that $(S, \ast)$ is a commutative monoid if it is a monoid and the operation satisfies the commutative law. That is,
  \[
    \forall x, y \in S, \quad x \ast y = y \ast x
  \]
\end{definition}

\begin{proposition}{unique of identity element}{uniqueness_of_identity_element}
  Let $(S, \cdot)$ be a monoid. Then the identity element is unique.
\end{proposition}
\begin{proof}
  Suppose that $e$ and $e'$ are both identity elements of $S$. Then
  \[
    e = e \cdot e' = e'
  \]
  so $e = e'$.
\end{proof}

\begin{proposition}{expand of associative law}{expand_of_associative_law}
  Let $x_1, \ldots, x_n, y_1, \ldots, y_m \in S$. Then
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
\end{proposition}
\begin{proof}
  We prove this by induction on $n$.

  \textbf{Base Case ($n = 1$):}
  When $n = 1$, the statement simplifies to:
  \[
    x_1 \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = x_1 \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
  This is clearly true by the associative property of multiplication.

  \textbf{Inductive Step:}
  Assume the statement holds for $n = k$, that is:
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
  We need to show that the statement holds for $n = k + 1$. Consider:
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1} \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m
  \]
  By the associative property, we can regroup the terms as:
  \[
    (x_1 \cdot x_2 \cdot \ldots \cdot x_k ) \cdot (x_{k+1} \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
  Using the inductive hypothesis on the first $k$ terms, we have:
  \[
    (x_1 \cdot x_2 \cdot \ldots \cdot x_k) \cdot x_{k+1} \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m) = (x_1 \cdot x_2 \cdot \ldots \cdot x_k \cdot x_{k+1}) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]
  Thus, the statement holds for $n = k + 1$.

\end{proof}

\begin{proposition}
  Let $x \in S$ and $m,n \in \mathbb{N}$. Then
  \[
    x^{m+n} = x^m \cdot x^n
  \]
\end{proposition}
\begin{proof}
  We will prove this in three steps:

  \textbf{Step 1:} First, recall from Proposition~\ref{pro:expand_of_associative_law} that for any elements in $S$:
  \[
    x_1 \cdot x_2 \cdot \ldots \cdot x_n \cdot y_1 \cdot y_2 \cdot \ldots \cdot y_m = (x_1 \cdot x_2 \cdot \ldots \cdot x_n) \cdot (y_1 \cdot y_2 \cdot \ldots \cdot y_m)
  \]

  \textbf{Step 2:} Now, consider the special case where all elements are equal to $x$:
  \begin{itemize}
    \item Let $x_1 = x_2 = \ldots = x_m = x$
    \item Let $y_1 = y_2 = \ldots = y_n = x$
  \end{itemize}

  \textbf{Step 3:} By definition of exponentiation in a monoid:
  \begin{align*}
    x^{m+n} &= \underbrace{x \cdot x \cdot \ldots \cdot x}_{m+n \text{ times}} \\
    &= (\underbrace{x \cdot x \cdot \ldots \cdot x}_{m \text{ times}}) \cdot (\underbrace{x \cdot x \cdot \ldots \cdot x}_{n \text{ times}}) \\
    &= x^m \cdot x^n
  \end{align*}

  Therefore, we have proved that $x^{m+n} = x^m \cdot x^n$ for all $x \in S$ and $m,n \in \mathbb{N}$.
\end{proof}

\begin{definition}{Submonoid}{submonoid}
  Let $(S,\cdot)$ be a monoid. If $T \subset S$, we say that $(T,\cdot)$ is a submonoid of $(S,\cdot)$ if:
  \begin{enumerate}
    \item The identity element $e \in T$
    \item $T$ is closed under multiplication, that is:
      \[
        \forall x,y \in T, \quad x \cdot y \in T
      \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  If $(T,\cdot)$ is a submonoid of $(S,\cdot)$, then $(T,\cdot)$ is a monoid.
\end{proposition}
\begin{proof}
  We need to verify two properties:
  \begin{enumerate}
    \item The operation is associative in $T$: \\
      Since $T \subset S$ and $\cdot$ is associative in $S$, it is also associative in $T$.

    \item $T$ has an identity element: \\
      By definition of submonoid, the identity element $e \in T$.
  \end{enumerate}
  Therefore, $(T,\cdot)$ satisfies all properties of a monoid.
\end{proof}

\begin{definition}[Monoid Homomorphism]{monoid_homomorphism}
  Let $(S,\cdot)$ and $(T,\ast)$ be monoids, and let $f : S \to T$ be a mapping.
  We say $f$ is a monoid homomorphism if $f$ preserves multiplication and maps the identity element to the identity element. That is:
  \begin{enumerate}
    \item For all $x,y \in S$:
      \[
        f(x \cdot y) = f(x) \ast f(y)
      \]
    \item For the identity elements $e \in S$ and $e' \in T$:
      \[
        f(e) = e'
      \]
  \end{enumerate}
\end{definition}

\begin{remark}
  While a homomorphism preserves operations, an isomorphism represents complete structural equivalence. An isomorphism is first a \textbf{bijective mapping}, meaning it establishes a one-to-one correspondence between elements - essentially ``relabeling" elements uniquely. Beyond being bijective, an isomorphism preserves operations under this relabeling, implying that the only difference between two structures (like monoids) is their labeling.
\end{remark}

\begin{example}[~Different Types of Monoid Maps]
  Let's examine several maps between monoids:

  \begin{enumerate}
    \item \textbf{A homomorphism that is not an isomorphism:}
      Consider $f: (\mathbb{Z}, +) \to (\mathbb{Z}, +)$ defined by $f(n) = 2n$
      \begin{itemize}
        \item Preserves operation: $f(a + b) = 2(a + b) = 2a + 2b = f(a) + f(b)$
        \item Is injective: $f(a) = f(b) \implies 2a = 2b \implies a = b$
        \item Not surjective: odd numbers are not in the image
        \item Therefore: homomorphism but not isomorphism
      \end{itemize}
    \item \textbf{Non-isomorphic homomorphism:}
      Consider $h: (\mathbb{Z}, +) \to (\mathbb{Z}_2, +)$ defined by $h(n) = n \bmod 2$
      \begin{itemize}
        \item Preserves operation: $h(a + b) = (a + b) \bmod 2 = (a \bmod 2 + b \bmod 2) \bmod 2 = h(a) + h(b)$
        \item Not injective: $h(0) = h(2) = 0$
        \item Surjective: image is all of $\mathbb{Z}_2$
        \item Therefore: homomorphism but not isomorphism
      \end{itemize}
  \end{enumerate}
\end{example}

\begin{definition}[Generated Submonoid]
  Let $(S,\cdot)$ be a monoid and $A \subset S$ be a subset. The submonoid generated by $A$, denoted by $\langle A \rangle$, is defined as the intersection of all submonoids of $S$ containing $A$. That is:
  \[
    \langle A \rangle = \bigcap \{T \subset S : T \supset A, \text{ $T$ is a submonoid}\}
  \]
\end{definition}

\begin{proposition}
  Let $(S,\cdot)$ be a monoid and $A \subset S$ be a subset. Then $\langle A \rangle$ is also a submonoid. Therefore, it is the smallest submonoid containing $A$.
\end{proposition}
\begin{proof}
  We will prove this in two steps:

  \textbf{Step 1:} Show $\langle A \rangle$ contains the identity element

  Let $\{T_\alpha\}_{\alpha \in I}$ be the collection of all submonoids containing $A$,
  Each $T_\alpha$ contains the identity $e$ (by definition of submonoid),
  Therefore $e \in \bigcap_{\alpha \in I} T_\alpha = \langle A \rangle$

  \textbf{Step 2:} Show closure under multiplication

  Let $x, y \in \langle A \rangle = \bigcap_{\alpha \in I} T_\alpha$,
  Then $x, y \in T_\alpha$ for all $\alpha \in I$
  Since each $T_\alpha$ is a submonoid, $x \cdot y \in T_\alpha$ for all $\alpha \in I$,
  Therefore $x \cdot y \in \bigcap_{\alpha \in I} T_\alpha = \langle A \rangle$.

\end{proof}

\begin{definition}[Monoid Isomorphism]
  Let $(S,\cdot)$ and $(T,\ast)$ be monoids, and let $f : S \to T$ be a mapping. We say $f$ is a monoid isomorphism if $f$ is bijective and a homomorphism. That is:
  \begin{enumerate}
    \item $f$ is bijective (one-to-one and onto)
    \item For all $x,y \in S$:
      \[
        f(x \cdot y) = f(x) \ast f(y)
      \]
    \item For the identity elements $e \in S$ and $e' \in T$:
      \[
        f(e) = e'
      \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  If $f : (S,\cdot) \to (T,\ast)$ is a monoid isomorphism, then $f^{-1} : T \to S$ is a monoid homomorphism. Therefore, $f^{-1}$ is also a monoid isomorphism.
\end{proposition}

\begin{proof}
  Since $f$ is an isomorphism, $f^{-1}$ exists and is bijective. We need to show:
  \begin{enumerate}
    \item $f^{-1}$ preserves operation:
      \begin{align*}
        f^{-1}(a \ast b) &= f^{-1}(f(f^{-1}(a)) \ast f(f^{-1}(b))) \\
        &= f^{-1}(f(f^{-1}(a) \cdot f^{-1}(b))) \\
        &= f^{-1}(a) \cdot f^{-1}(b)
      \end{align*}

    \item $f^{-1}$ preserves identity:
      \[
        f^{-1}(e') = e \text{ where $e'$ and $e$ are identity elements}
      \]
  \end{enumerate}
  Therefore, $f^{-1}$ is both a homomorphism and bijective, making it an isomorphism.
\end{proof}

\section{Group}

\begin{definition}[Invertible Element]{invertible_element}
  Let $(S,\cdot)$ be a monoid and $x \in S$. We say $x$ is invertible if and only if
  \[
    \exists y \in S, x \cdot y = y \cdot x = e
  \]
  where $y$ is called the inverse of $x$, denoted as $x^{-1}$.
\end{definition}

\begin{proposition}[Uniqueness of Inverse]{uniqueness_of_inverse}
  Let $(S,\cdot)$ be a monoid. If $x \in S$ is invertible, then its inverse is unique. That is, if $y,y' \in S$ are both inverses of $x$, then $y = y'$.
\end{proposition}

\begin{proof}
  Let $y$ and $y'$ be inverses of $x$. Then:
  \begin{align*}
    y &= y \cdot e \\
    &= y \cdot (x \cdot y') \\
    &= (y \cdot x) \cdot y' \\
    &= e \cdot y' \\
    &= y'
  \end{align*}
  Therefore, the inverse is unique.
\end{proof}

\begin{definition}[Group]{group}
  Let $(G,\cdot)$ be a monoid. We say it is a group if every element in $G$ is invertible.

  Equivalently, if $\cdot$ is a binary operation on $G$, we say $(G,\cdot)$ is a group, or $G$ forms a group under $\cdot$, when this operation satisfies:
  \begin{enumerate}
    \item Associativity: For all $x,y,z \in G$
      \[
        x \cdot (y \cdot z) = (x \cdot y) \cdot z
      \]

    \item Identity element: There exists $e \in G$ such that for all $x \in G$
      \[
        x \cdot e = e \cdot x = x
      \]

    \item Inverse elements: For each $x \in G$, there exists $y \in G$ such that
      \[
        x \cdot y = y \cdot x = e
      \]
  \end{enumerate}
\end{definition}

\begin{proposition}
  Let $(G,\cdot)$ be a group and $x \in G$. Then $(x^{-1})^{-1} = x$.
\end{proposition}

\begin{proof}
  Let $y = x^{-1}$. Then:
  \[
    y \cdot x = x \cdot y = e
  \]
  This shows that $x$ is the inverse of $y = x^{-1}$.
  Therefore, $(x^{-1})^{-1} = x$.
\end{proof}

\begin{proposition}[Inverse of Product]
  Let $(G,\cdot)$ be a group and $x,y \in G$. Then $(x \cdot y)^{-1} = y^{-1} \cdot x^{-1}$.
\end{proposition}

\begin{proof}
  We will show that $y^{-1} \cdot x^{-1}$ is the inverse of $x \cdot y$:
  \begin{align*}
    (x \cdot y)(y^{-1} \cdot x^{-1}) &= x \cdot (y \cdot y^{-1}) \cdot x^{-1} \\
    &= x \cdot e \cdot x^{-1} \\
    &= x \cdot x^{-1} \\
    &= e
  \end{align*}
  Similarly, $(y^{-1} \cdot x^{-1})(x \cdot y) = e$.
  Therefore, $(x \cdot y)^{-1} = y^{-1} \cdot x^{-1}$.
\end{proof}

\begin{definition}[Abelian Group]{abelian_group}
  Let $(G,\cdot)$ be a group. We say it is an abelian group, or commutative group, if the operation satisfies the commutative law:
  \[
    \forall x,y \in G, \quad x \cdot y = y \cdot x
  \]
\end{definition}

\begin{lemma}
  Let $(S,\cdot)$ be a monoid and let $G$ be the subset of all invertible elements in $S$. Then $(G,\cdot)$ is a group.
\end{lemma}

\begin{proof}
  We need to verify three group axioms:
  \begin{enumerate}
    \item Closure: If $x,y \in G$, then $x \cdot y \in G$ (as product of invertible elements is invertible)
    \item Identity: $e \in G$ (as $e$ is invertible)
    \item Inverse: If $x \in G$, then $x^{-1} \in G$ (by definition of invertible elements)
  \end{enumerate}
  Associativity is inherited from $S$. Therefore, $(G,\cdot)$ is a group.
\end{proof}

\begin{definition}[General Linear Group]{general_linear_group}
  The group of $n \times n$ invertible real matrices under matrix multiplication is called the general linear group of degree $n$ over the real numbers, denoted as $(GL(n,\mathbb{R}),\cdot)$. Since a matrix is invertible if and only if its determinant is nonzero:
  \[
    GL(n,\mathbb{R}) = \{ A \in M(n,\mathbb{R}) : \det(A) \neq 0 \}
  \]
\end{definition}

\begin{definition}[Special Linear Group]
  The special linear group of degree $n$ over the real numbers is the group of $n \times n$ real matrices with determinant exactly $1$ under matrix multiplication, denoted as $(SL(n,\mathbb{R}),\cdot)$. That is:
  \[
    SL(n,\mathbb{R}) = \{ A \in M(n,\mathbb{R}) : \det(A) = 1 \}
  \]
\end{definition}

\begin{definition}[Subgroup]{subgroup}
  Let $(G,\cdot)$ be a group and $H \subset G$. We say $H$ is a subgroup of $G$, denoted as $H < G$, if it contains the identity element and is closed under multiplication and inverse operations. That is:
  \begin{enumerate}
    \item $\forall x,y \in H, \quad x \cdot y \in H$ \quad (closure under multiplication)
    \item $\forall x \in H, \quad x^{-1} \in H$ \quad (closure under inverse)
    \item $e \in H$ \quad (contains identity)
  \end{enumerate}
\end{definition}

\begin{proposition}
  Let $(G,\cdot)$ be a group. If $H$ is a subgroup of $G$, then $(H,\cdot)$ is also a group.
\end{proposition}

\begin{proof}
  Since $H$ is a subgroup:
  \begin{enumerate}
    \item Associativity: Inherited from $G$
    \item Identity: $e \in H$ by definition of subgroup
    \item Inverse: For all $x \in H$, $x^{-1} \in H$ by definition of subgroup
    \item Closure: For all $x,y \in H$, $x \cdot y \in H$ by definition of subgroup
  \end{enumerate}
  Therefore, $(H,\cdot)$ satisfies all group axioms.
\end{proof}

\begin{proposition}
  For convenience, we can combine the first two conditions of a subgroup definition~\ref{def:subgroup} into one, reducing to two conditions:
  \begin{enumerate}
    \item $\forall x,y \in H, \quad x \cdot y^{-1} \in H$
    \item $e \in H$
  \end{enumerate}
  These conditions are equivalent to the original subgroup definition.
\end{proposition}

\begin{proof}

  ($\Rightarrow$)  $\forall y \in H$, $y^{-1} \in H$, then the closure under multiplication,  $\forall x,y,y^{-1} \in H$, $x \cdot y^{-1} \in H$

  ($\Leftarrow$) $\forall x,y \in H$, $x \cdot y^{-1} \in H$, let $x=e$, then have $\forall y\in H$, $y^{-1} \in H$; so $\forall x,y^{-1}\in H$, $x \cdot (y^{-1})^{-1} \in H$, then $x \cdot y \in H$.
\end{proof}

\begin{proposition}
  $(SL(n,\mathbb{R}),\cdot)$ is a group.
\end{proposition}

\begin{proof}
  We verify the group axioms:
  \begin{enumerate}
    \item Closure: If $A,B \in SL(n,\mathbb{R})$, then $\det(AB) = \det(A)\det(B) = 1 \cdot 1 = 1$, so $AB \in SL(n,\mathbb{R})$

    \item Identity: The identity matrix $I_n \in SL(n,\mathbb{R})$ since $\det(I_n) = 1$

    \item Inverse: If $A \in SL(n,\mathbb{R})$, then $\det(A^{-1}) = \frac{1}{\det(A)} = 1$, so $A^{-1} \in SL(n,\mathbb{R})$

    \item Associativity: Inherited from matrix multiplication
  \end{enumerate}
  Therefore, $(SL(n,\mathbb{R}),\cdot)$ is a group.
\end{proof}

\begin{definition}[Group Homomorphism]
  Let $(G,\cdot)$ and $(G',\ast)$ be groups, and let $f : G \to G'$ be a mapping. We say $f$ is a group homomorphism if it preserves the operation, that is:
  \[
    \forall x,y \in G, \quad f(x \cdot y) = f(x) \ast f(y)
  \]
\end{definition}

\begin{proposition}
  Let $f : (G,\cdot) \to (G',\ast)$ be a group homomorphism. Then:
  \begin{enumerate}
    \item $f(e) = e'$ (preserves identity)
    \item $f(x^{-1}) = f(x)^{-1}$ (preserves inverses)
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{enumerate}
    \item For identity element:
      \begin{align*}
        f(e) \ast f(e) &= f(e \cdot e) = f(e) \quad \text{left multiply by $f(e)^{-1}$} \\
        \therefore f(e) &= e'
      \end{align*}
    \item For inverse elements:
      \begin{align*}
        f(x) \ast f(x^{-1}) &= f(x \cdot x^{-1}) = f(e) = e' \quad \text{left multiply by $f(x)^{-1}$} \\
        \therefore f(x^{-1}) &= f(x)^{-1}
      \end{align*}
  \end{enumerate}
\end{proof}
