{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to be able to encode and decode the information in a manner that will allow the detection, and possibly the correction, of errors caused by noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 8.1 Error-Detecting and Correcting Codes\n",
    "\n",
    "Uncoded messages may be composed of letters or characters, but typically they consist of binary $m$-tuples. These messages are encoded into codewords consisting of binary $n$-tuples, by a device called an **encoder**. The message is transmitted and then decoded. We will consider the occurrence of errors during transmission. An error occurs if there is a change in one or more bits in the codeword. A **decoding** scheme is a method that either converts an arbitrarily received $n$-tuple into a meaningful decoded message or gives an error message for that $n$-tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The even parity system is easy to implement, but has two drawbacks. First, **multiple errors** are not detectable. Suppose an $A$ is sent and the first and seventh bits are changed from 0 to 1. The received word is a codeword, but will be decoded into a $C$ instead of an $A$. Second, we do not have the ability to **correct errors**. If the 8-tuple $(\\text{1001 1000})$ is received, we know that an error has occurred, but we have no idea which bit has been changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum-Likelihood Decoding\n",
    "\n",
    "We will also assume that a received $n$-tuple is decoded into a codeword that is closest to it; that is, we assume that the receiver uses **maximum-likelihood decoding**.\n",
    "\n",
    "A **binary symmetric channel** is a model that consists of a transmitter capable of sending a binary signal, either a 0 or a 1, together with a receiver. Let $p$ be the probability that the signal is correctly received. Then $q = 1 - p$ is the probability of an incorrect reception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 8.7** If a binary $n$-tuple $(x_1, \\ldots, x_n)$ is transmitted across a binary symmetric channel with probability $p$ that no error will occur in each coordinate, then the probability that there are errors in exactly $k$ coordinates is\n",
    "$$\n",
    "\\binom{n}{k} q^k p^{n-k}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Codes\n",
    "\n",
    "A code is an $(n,m)$-**block code** if the information that is to be coded\n",
    "can be divided into blocks of $m$ binary digits, each of which can be encoded into $n$ binary digits. More specifically, an $(n,m)$-block code consists of an **encoding function**\n",
    "$$\n",
    "E : \\mathbb{Z}_2^m \\to \\mathbb{Z}_2^n\n",
    "$$\n",
    "and a **decoding function**\n",
    "$$\n",
    "D : \\mathbb{Z}_2^n \\to \\mathbb{Z}_2^m.\n",
    "$$\n",
    "A **codeword** is any element in the image of $E$. We also require that $E$ be **one-to-one** so that two information blocks will not be encoded into the same codeword. If our code is to be error-correcting, then $D$ must be **onto**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x = (x_1, \\ldots, x_n)$ and $y = (y_1, \\ldots, y_n)$ be binary $n$-tuples. The **Hamming distance** or distance, $d(x, y)$, between $x$ and $y$ is the number of bits in which $x$ and $y$ differ. The distance between two codewords is the minimum number of transmission errors required to change\n",
    "one codeword into the other. The **minimum distance** for a code, $d_{\\min}$, is the minimum of all distances $d(x, y)$, where $x$ and $y$ are distinct codewords. The **weight**, $w(x)$, of a binary codeword $x$ is the number of 1s in $x$. Clearly, $w(x) = d(x, 0)$, where $0 = (0, 0, \\ldots, 0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Proposition 8.11** Let $x$, $y$, and $z$ be binary $n$-tuples. Then\n",
    "1. $w(x) = d(x, 0)$;\n",
    "2. $d(x, y) \\geq 0$;\n",
    "3. $d(x, y) = 0$ exactly when $x = y$;\n",
    "4. $d(x, y) = d(y, x)$;\n",
    "5. $d(x, y) \\leq d(x, z) + d(z, y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 8.13** Let $C$ be a code with $d_{\\min} = 2n + 1$. Then $C$ can correct any $n$ or fewer errors. Furthermore, any $2n$ or fewer errors can be detected in $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 8.2 Linear Codes\n",
    "\n",
    "A **group code** is a code that is also a subgroup of $\\mathbb{Z}_2^n$.\n",
    "To check that a code is a group code, we need only verify one thing. If we add any two elements in the code, the result must be an $n$-tuple that is again in the code. It is not necessary to check that the inverse of the $n$-tuple is in the code, since every codeword is its own inverse, nor is it necessary to check that $0$ is a codeword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemma 8.17** Let $x$ and $y$ be binary $n$-tuples. Then $w(x + y) = d(x, y)$.\n",
    "\n",
    "**Theorem 8.18** Let $d_{\\min}$ be the minimum distance for a group code $C$. Then $d_{\\min}$ is the minimum weight of all the nonzero codewords in $C$. That is,\n",
    "$$\n",
    "d_{\\min} = \\min\\{w(x) : x \\neq 0\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Linear Codes\n",
    "\n",
    "Define the **inner product** of two binary $n$-tuples to be\n",
    "$$\n",
    "x \\cdot y = x_1 y_1 + \\cdots + x_n y_n,\n",
    "$$\n",
    "where $x = (x_1, x_2, \\ldots, x_n)^t$ and $y = (y_1, y_2, \\ldots, y_n)^t$ are column vectors. For example, if $x = (011001)^t$ and $y = (110101)^t$, then $x \\cdot y = 0$. We can also look at an inner product as the product of a row matrix with a column matrix; that is,\n",
    "$$\n",
    "x \\cdot y = x^t y =\n",
    "\\begin{pmatrix}\n",
    "x_1 & x_2 & \\cdots & x_n\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}.\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
